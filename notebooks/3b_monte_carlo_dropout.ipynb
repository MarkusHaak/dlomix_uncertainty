{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198d9ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install https://github.com/MarkusHaak/dlomix/ with pip\n",
    "# OR uncomment to insert its path with sys:\n",
    "#import os, sys\n",
    "#sys.path.insert(0, os.path.abspath('../../dlomix/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d116a481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seeds for reproducibility\n",
    "from dlomix.utils import set_global_seed\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b3b2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import dlomix\n",
    "from dlomix import constants, data, eval, layers, models, pipelines, reports, utils\n",
    "from time import time\n",
    "import traceback\n",
    "from tqdm import tqdm\n",
    "from dlomix.data import RetentionTimeDataset\n",
    "from dlomix.models import PrositRetentionTimePredictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c75c75d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet using the same PTM identifiers as in the created datasets\n",
    "ALPHABET_MOD = {\n",
    "    \"A\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "    \"H\": 7,\n",
    "    \"I\": 8,\n",
    "    \"K\": 9,\n",
    "    \"L\": 10,\n",
    "    \"M\": 11,\n",
    "    \"N\": 12,\n",
    "    \"P\": 13,\n",
    "    \"Q\": 14,\n",
    "    \"R\": 15,\n",
    "    \"S\": 16,\n",
    "    \"T\": 17,\n",
    "    \"V\": 18,\n",
    "    \"W\": 19,\n",
    "    \"Y\": 20,\n",
    "    \"^\": 21,\n",
    "    \"}\": 22,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277598b0",
   "metadata": {},
   "source": [
    "# Monte Carlo Dropout\n",
    "\n",
    "Perform Monte Carlo Dropout (MCD) by loading the individual models from weights and calling them with active dropout on the calibration and test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f013e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_with_dropout(model, test_data, n=50):\n",
    "    predictions = []\n",
    "    for i in tqdm(range(n)):\n",
    "        res = np.concatenate([model(batch[0], training=True).numpy() for batch in list(test_data)])\n",
    "        predictions.append(res)\n",
    "    return np.column_stack(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d9afb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define which n's to use for later analysis\n",
    "Ns = [3,5,10,20,30,50,100]\n",
    "models = {'PRT_med':\"./output_median/cv{}/best\",\n",
    "          'PRT_sel10':\"./output_sel10/cv{}/best\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b38d94b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = {}\n",
    "res_calib = {}\n",
    "res_sel10 = {}\n",
    "res_calib_sel10 = {}\n",
    "for cv in range(1,6):\n",
    "    BATCH_SIZE = 256\n",
    "    \n",
    "    # load calibration data for the respective cross-validation split, and the test data\n",
    "    # mdeian dataset\n",
    "    CALIBRATION_DATAPATH = f'../data/PROSPECT_median_calibration{cv}.csv'\n",
    "    calibration_rtdata = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                       seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                       sequence_col='modified_sequence_single_letter',\n",
    "                                       target_col='median')\n",
    "    TEST_DATAPATH = '../data/PROSPECT_median_holdout_cv.csv'\n",
    "    test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                       seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                       sequence_col='modified_sequence_single_letter',\n",
    "                                       target_col='median')\n",
    "    test_targets = test_rtdata.get_split_targets(split=\"test\")\n",
    "    # sel10 dataset\n",
    "    CALIBRATION_DATAPATH = f'../data/PROSPECT_sel10_calibration{cv}.csv'\n",
    "    calibration_rtdata_sel10 = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                       seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                       sequence_col='modified_sequence_single_letter',\n",
    "                                       target_col='indexed_retention_time')\n",
    "    TEST_DATAPATH = '../data/PROSPECT_sel10_holdout_cv.csv'\n",
    "    test_rtdata_sel10 = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                       seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                       sequence_col='modified_sequence_single_letter',\n",
    "                                       target_col='indexed_retention_time')\n",
    "    test_targets_sel10 = test_rtdata_sel10.get_split_targets(split=\"test\")\n",
    "    # perform MCD\n",
    "    for l,model_save_path in models.items():\n",
    "        for res_dict, data_save_path, data in [(res, f'MCD_{l}_cv{cv}_data.npy', test_rtdata.test_data), \n",
    "                                               (res_calib, f'MCD_{l}_cv{cv}_calib.npy', calibration_rtdata.test_data),\n",
    "                                               (res_sel10, f'MCD_{l}_cv{cv}_sel10_data.npy', test_rtdata_sel10.test_data), \n",
    "                                               (res_calib_sel10, f'MCD_{l}_cv{cv}_sel10_calib.npy', calibration_rtdata_sel10.test_data)\n",
    "                                              ]:\n",
    "            # load the respective model from weights\n",
    "            model_save_path = model_save_path.format(cv)\n",
    "            print(l, cv, model_save_path, data_save_path)\n",
    "            # skip if predictions were already performed (in case notebook crashed)\n",
    "            if os.path.exists(data_save_path):\n",
    "                with open(data_save_path, 'rb') as f:\n",
    "                    pred = np.load(f)\n",
    "            else:\n",
    "                set_global_seed(42)\n",
    "                model = PrositRetentionTimePredictor(seq_length=30, vocab_dict=ALPHABET_MOD)\n",
    "                model.load_weights(model_save_path).expect_partial()\n",
    "                try:\n",
    "                    pred = predict_with_dropout(model, data, n=Ns[-1])\n",
    "                except:\n",
    "                    print(\"ERROR !!!\")\n",
    "                    print(traceback.format_exc())\n",
    "                    continue\n",
    "                with open(data_save_path, 'wb') as f:\n",
    "                    np.save(f, pred)\n",
    "            # store results\n",
    "            for n in Ns:\n",
    "                label = f\"{l}_n={n}\"\n",
    "                if label not in res_dict:\n",
    "                    res_dict[label] = {}\n",
    "                res_dict[label][cv] = {}\n",
    "                res_dict[label][cv]['data'] = np.array((pred[:,:n].mean(axis=1), pred[:,:n].std(axis=1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997f4b5e",
   "metadata": {},
   "source": [
    "# Conformal Prediction for scalar MCD results\n",
    "\n",
    "Apply conformal Prediction (scalar version) with alpha = 0.1 to assure marginal coverage of 0.9 for each model.\n",
    "The same is done for a randomized background model that is identical to the original model with respect to the heuristic interval sizes, but they are randomly reassociated betwee the test datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c791c5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dlomix.eval.scalar_conformal import ScalarConformalScore, ScalarConformalQuantile\n",
    "from dlomix.reports.MonteCarloReport import MonteCarloReport\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1819b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "for r, r_calib, ds in [(res_sel10, res_calib_sel10, 'sel10'), (res, res_calib, 'median')]\n",
    "    for label in r:\n",
    "        for cv in range(1,6):\n",
    "            # skip in case computation failed / was not performed yet\n",
    "            if cv not in r[label] or cv not in r_calib[label]:\n",
    "                continue\n",
    "            # load calibration data for the respective cross-validation split, and the test data\n",
    "            if ds == 'median':\n",
    "                CALIBRATION_DATAPATH = f'../data/PROSPECT_median_calibration{cv}.csv'\n",
    "                calibration_rtdata = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                                   seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                                   sequence_col='modified_sequence_single_letter',\n",
    "                                                   target_col='median')\n",
    "                calibration_targets = calibration_rtdata.get_split_targets(split=\"test\")\n",
    "                TEST_DATAPATH = '../data/PROSPECT_median_holdout_cv.csv'\n",
    "                test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                                   seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                                   sequence_col='modified_sequence_single_letter',\n",
    "                                                   target_col='median')\n",
    "                test_targets = test_rtdata.get_split_targets(split=\"test\")\n",
    "            else:\n",
    "                CALIBRATION_DATAPATH = f'../data/PROSPECT_sel10_calibration{cv}.csv'\n",
    "                calibration_rtdata = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                                   seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                                   sequence_col='modified_sequence_single_letter',\n",
    "                                                   target_col='indexed_retention_time')\n",
    "                calibration_targets = calibration_rtdata.get_split_targets(split=\"test\")\n",
    "                TEST_DATAPATH = '../data/PROSPECT_sel10_holdout_cv.csv'\n",
    "                test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                                   seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                                   sequence_col='modified_sequence_single_letter',\n",
    "                                                   target_col='indexed_retention_time')\n",
    "                test_targets = test_rtdata.get_split_targets(split=\"test\")\n",
    "            \n",
    "            # perform conformalization\n",
    "            print(f'#### {label} {cv} ####')\n",
    "            conf_scores = ScalarConformalScore(reduction='none')(calibration_targets, r_calib[label][cv]['data'].T).numpy()\n",
    "            conf_quantile = ScalarConformalQuantile()(calibration_targets, r_calib[label][cv]['data'].T).numpy()\n",
    "            print(f\"alpha = {alpha}, conformal quantile: {conf_quantile:.2f}\")\n",
    "            avgs, stds = r[label][cv]['data'][0], r[label][cv]['data'][1]\n",
    "            intervals = np.array([avgs - stds * conf_quantile, avgs + stds * conf_quantile]).T\n",
    "            interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "            within = (test_targets >= intervals[:,0]) & (test_targets <= intervals[:,1])\n",
    "            \n",
    "            # plot results\n",
    "            MonteCarloReport.plot_conformal_scores(conf_scores, quantile=conf_quantile)\n",
    "            MonteCarloReport.plot_predictions_with_intervals(test_targets, avgs, intervals)\n",
    "            MonteCarloReport.plot_conformalized_interval_size(interval_sizes)\n",
    "\n",
    "            pvalue = ks_2samp(interval_sizes[within], interval_sizes[~within]).pvalue # prob. for Null: distr are identical\n",
    "            print(f\"p = {pvalue:.5f} : {'Reject' if pvalue < 0.01 else 'Accept'} Null Hypothesis (Distr. identical)\")\n",
    "\n",
    "            MonteCarloReport.plot_conformalized_interval_size_PDFs(interval_sizes, within, pvalue)\n",
    "\n",
    "            # store results\n",
    "            r[label][cv]['conf_scores'] = conf_scores\n",
    "            r[label][cv]['conf_quantile'] = conf_quantile\n",
    "            r[label][cv]['intervals'] = intervals\n",
    "            r[label][cv]['within'] = within\n",
    "            r[label][cv]['conf_scores_test'] = ScalarConformalScore(reduction='none')(test_targets, r[label][cv]['data'].T).numpy()\n",
    "            r[label][cv]['pvalue'] = pvalue\n",
    "\n",
    "            # calculate a random background model, then perfrom conformalization as above\n",
    "            np.random.seed(42)\n",
    "            p = np.random.permutation(r_calib[label][cv]['data'].T.shape[0])\n",
    "            permuted_ivs = r_calib[label][cv]['data'].T.copy()\n",
    "            permuted_ivs = np.column_stack([permuted_ivs[:,0], permuted_ivs[:,1][p]])\n",
    "            conf_scores = ScalarConformalScore(reduction='none')(calibration_targets, permuted_ivs).numpy()\n",
    "            conf_quantile = ScalarConformalQuantile()(calibration_targets, permuted_ivs).numpy()\n",
    "            np.random.seed(cv)\n",
    "            p = np.random.permutation(r[label][cv]['data'].T.shape[0])\n",
    "            avgs, stds = r[label][cv]['data'][0], r[label][cv]['data'][1][p]\n",
    "            intervals = np.array([avgs - stds * conf_quantile, avgs + stds * conf_quantile]).T\n",
    "            interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "            within = (test_targets >= intervals[:,0]) & (test_targets <= intervals[:,1])\n",
    "            r[label][cv]['rnd_conf_scores'] = conf_scores\n",
    "            r[label][cv]['rnd_conf_quantile'] = conf_quantile\n",
    "            r[label][cv]['rnd_intervals'] = intervals\n",
    "            r[label][cv]['rnd_within'] = within"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f7a081",
   "metadata": {},
   "source": [
    "# Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "040e2781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ee914ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/MonteCarloDropout_results_with_rnd.pkl\", 'wb') as f:\n",
    "    pickle.dump(res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744e25e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/MonteCarloDropout_results_calibration_with_rnd.pkl\", 'wb') as f:\n",
    "    pickle.dump(res_calib, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970548fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/MonteCarloDropout_results_sel10_with_rnd.pkl\", 'wb') as f:\n",
    "    pickle.dump(res_sel10, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf4dece",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/MonteCarloDropout_results_calibration_sel10_with_rnd.pkl\", 'wb') as f:\n",
    "    pickle.dump(res_calib_sel10, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
