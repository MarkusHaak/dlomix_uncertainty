{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b8d7e3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from scipy.stats import skew\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import pyplot as plt, colors\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eec9db03",
   "metadata": {},
   "source": [
    "# Read all PROSPECT parquet files\n",
    "\n",
    "All .parquet files of the PROSPECT dataset need to be downloaded and saved to \"../data/\" prior to running this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700e2e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"../data/\"\n",
    "dfs = []\n",
    "for fn in [os.path.join(data_dir, fn) for fn in os.listdir(data_dir) if fn.endswith('parquet')]:\n",
    "    dfs.append(pd.read_parquet(fn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4f464b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat(dfs)\n",
    "df = df.reset_index()\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3962fd32",
   "metadata": {},
   "source": [
    "# Filter\n",
    "\n",
    "Remove entries with missing values or with a low ANDROMEDA score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de41e66",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing data\n",
    "to_remove = pd.isnull(df.raw_file) | pd.isnull(df.scan_number) | \\\n",
    "            pd.isnull(df.indexed_retention_time) | pd.isnull(df.modified_sequence) | \\\n",
    "            pd.isnull(df.andromeda_score)\n",
    "print(\"# removed due to missing data:\", to_remove.sum())\n",
    "df = df.loc[~to_remove]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c238f4ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select most likely sequence assignments\n",
    "df = df.sort_values('andromeda_score').groupby(['raw_file', 'scan_number']).head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df997d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.andromeda_score.hist(bins=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2693685",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove low-quality sequence assignments\n",
    "df = df.loc[df.andromeda_score > 70.]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae1d3790",
   "metadata": {},
   "source": [
    "# Identify and replace PTMs\n",
    "\n",
    "Find unique unimod identifiers of post-translationally modified residues and replace them with a unique single-character identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73d9244a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_regex = '(.\\[UNIMOD:(.*?)\\])'\n",
    "all_mods = df.modified_sequence.str.findall(mod_regex).explode().unique()\n",
    "all_mods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd5c3f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_letter_encoding = {re.escape(unimod):chr(ord('Z') + int(val)) for unimod,val in all_mods[~pd.isnull(all_mods)]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad030309",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(single_letter_encoding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1184241",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['modified_sequence_single_letter'] = df.modified_sequence.replace(single_letter_encoding, regex=True)\n",
    "df.modified_sequence_single_letter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d60539",
   "metadata": {},
   "source": [
    "# Sample without replacement\n",
    "\n",
    "For each unique modified sequences, randomly sample up to 10 dataset entries without replacement to serve as samples in the \"sel10\" dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c638fde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "sel_str = f'sel{n}'\n",
    "df[sel_str] = False\n",
    "# shuffle df\n",
    "df = df.sample(frac=1, random_state=42)\n",
    "df.loc[df.groupby('modified_sequence_single_letter').head(n).index, sel_str] = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bc1a140",
   "metadata": {},
   "source": [
    "# Compute median values & statistics\n",
    "\n",
    "For all unique modified sequences, compute median indexed retention times and other statistics over all dataset entires with this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a3d22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "grpd = df.groupby('modified_sequence_single_letter')[['indexed_retention_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389a775d",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = grpd.agg(\n",
    "    cnt=('indexed_retention_time', 'count'),\n",
    "    std=('indexed_retention_time','std'),\n",
    "    median=('indexed_retention_time','median'),\n",
    "    mean=('indexed_retention_time','mean'),\n",
    "    min=('indexed_retention_time','min'),\n",
    "    max=('indexed_retention_time','max'),\n",
    "    skew=('indexed_retention_time',lambda X: skew(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d07aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['npstd'] = grpd.agg(np.std, ddof=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "965d2ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "del grpd # clear some memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43e526d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# std. dev. vs. counts per sequence plot\n",
    "fig,ax = plt.subplots(figsize=(9,7))\n",
    "hh = ax.hist2d(d['cnt'], d['std'], range=((0,2000),(0,25)), bins=500, norm=colors.LogNorm())\n",
    "fig.colorbar(hh[3], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa2b517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D-Histogram of group counts vs. median iRT\n",
    "fig,ax = plt.subplots(figsize=(9,7))\n",
    "hh = ax.hist2d(d['median'], d['cnt'], range=((-20,130), (0,2000)), bins=500, norm=colors.LogNorm())\n",
    "fig.colorbar(hh[3], ax=ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa7451f8",
   "metadata": {},
   "source": [
    "# Splitting & Exporting datasets\n",
    "\n",
    "6-fold Cross-Validation split (only 5 used later on) with fixed holdout set of the sel10 and median datasets. The two dataset-types are split identically (based on unique modified sequence)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daad787f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define 'sets' later used for composing cross-validation splits\n",
    "seqs_remaining, seqs_holdout = train_test_split(d.index, test_size=0.15, random_state=42) # 15 % holdout\n",
    "cv = 6\n",
    "partitions = []\n",
    "calibs = []\n",
    "for i in range(cv):\n",
    "    seqs_remaining, seqs_part = train_test_split(seqs_remaining, test_size=min(1.0, (0.85/cv - 0.02) / (0.85 - i*0.85/cv)), random_state=42)\n",
    "    try: \n",
    "        seqs_remaining,seqs_calib = train_test_split(seqs_remaining, test_size=min(1.0, 0.02 / (0.85 - i*0.85/cv - (0.85/cv - 0.02))), random_state=42)\n",
    "    except:\n",
    "        seqs_calib = seqs_remaining\n",
    "    calibs.append(seqs_calib)\n",
    "    partitions.append(seqs_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73671004",
   "metadata": {},
   "outputs": [],
   "source": [
    "d['set'] = ''\n",
    "for i in range(cv):\n",
    "    d.loc[partitions[i], 'set'] = f'cv{i}'\n",
    "    d.loc[calibs[i],     'set'] = f'cal{i}'\n",
    "d.loc[seqs_holdout,      'set'] = 'holdout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f62b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in ['holdout'] + [f'cv{i}' for i in range(cv)] + [f'cal{i}' for i in range(cv)]:\n",
    "    print(\"split {:<13} : {:>6} {:>5.2f} %\".format(split,len(d.loc[d.set == split]), len(d.loc[d.set == split]) / len(d) * 100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739c5a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['set'] = ''\n",
    "for i in range(cv):\n",
    "    df.loc[df.modified_sequence_single_letter.isin(partitions[i]), 'set'] = f'cv{i}'\n",
    "    df.loc[df.modified_sequence_single_letter.isin(calibs[i]), 'set'] = f'cal{i}'\n",
    "df.loc[df.modified_sequence_single_letter.isin(seqs_holdout), 'set'] = 'holdout'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b220ce22",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = d.sort_values('set').reset_index(drop=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e675844",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.sort_values('set').reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67669713",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose splits and export\n",
    "\n",
    "out_dir = \"../data/\"\n",
    "# export all data in one csv (as a savepoint and reference)\n",
    "df.to_csv(os.path.join(out_dir, 'PROSPECT_all_cv.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e914a56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose and export \"sel10\" CV splits\n",
    "cols = ['modified_sequence_single_letter', 'indexed_retention_time', 'andromeda_score']\n",
    "for i in range(cv):\n",
    "    training_sets = [f'cv{j}' for j in range(cv) if j != i] + [f'cal{j}' for j in range(cv) if j != i]\n",
    "    validation_sets = [f'cv{i}', f'cal{i}']\n",
    "    calibration_set = f'cal{i+1}' if i+1 < cv else 'cal0'\n",
    "    training_sets.remove(calibration_set)\n",
    "    df.loc[df.sel10 & (df.set.isin(training_sets))][cols].to_csv(os.path.join(out_dir, f'PROSPECT_sel10_training{i}.csv'))\n",
    "    df.loc[df.sel10 & (df.set.isin(validation_sets))][cols].to_csv(os.path.join(out_dir, f'PROSPECT_sel10_validation{i}.csv'))\n",
    "    df.loc[df.sel10 & (df.set == calibration_set)][cols].to_csv(os.path.join(out_dir, f'PROSPECT_sel10_calibration{i}.csv'))\n",
    "df.loc[df.sel10 & (df.set == 'holdout')][cols].to_csv(os.path.join(out_dir, f'PROSPECT_sel10_holdout_cv.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d01c311",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose and export \"median\" CV splits\n",
    "for i in range(cv):\n",
    "    training_sets = [f'cv{j}' for j in range(cv) if j != i] + [f'cal{j}' for j in range(cv) if j != i]\n",
    "    validation_sets = [f'cv{i}', f'cal{i}']\n",
    "    calibration_set = f'cal{i+1}' if i+1 < cv else 'cal0'\n",
    "    training_sets.remove(calibration_set)\n",
    "    d.loc[(d.set.isin(training_sets))].to_csv(os.path.join(out_dir, f'PROSPECT_median_training{i}.csv'))\n",
    "    d.loc[(d.set.isin(validation_sets))].to_csv(os.path.join(out_dir, f'PROSPECT_median_validation{i}.csv'))\n",
    "    d.loc[(d.set == calibration_set)].to_csv(os.path.join(out_dir, f'PROSPECT_median_calibration{i}.csv'))\n",
    "d.loc[(d.set == 'holdout')].to_csv(os.path.join(out_dir, f'PROSPECT_median_holdout_cv.csv'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
