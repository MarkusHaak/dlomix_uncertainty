{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a44e966",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install https://github.com/MarkusHaak/dlomix/ with pip\n",
    "# OR uncomment to insert its path with sys:\n",
    "#import os, sys\n",
    "#sys.path.insert(0, os.path.abspath('../../dlomix/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd998109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seeds for reproducibility\n",
    "from dlomix.utils import set_global_seed\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edc34e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import dlomix\n",
    "from dlomix import constants, data, eval, layers, models, pipelines, reports, utils\n",
    "from dlomix.data import RetentionTimeDataset\n",
    "from dlomix.models import PrositRetentionTimePredictor\n",
    "from dlomix.eval import TimeDeltaMetric\n",
    "from dlomix.reports import RetentionTimeReport"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b831d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet using the same PTM identifiers as in the created datasets\n",
    "ALPHABET_MOD = {\n",
    "    \"A\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "    \"H\": 7,\n",
    "    \"I\": 8,\n",
    "    \"K\": 9,\n",
    "    \"L\": 10,\n",
    "    \"M\": 11,\n",
    "    \"N\": 12,\n",
    "    \"P\": 13,\n",
    "    \"Q\": 14,\n",
    "    \"R\": 15,\n",
    "    \"S\": 16,\n",
    "    \"T\": 17,\n",
    "    \"V\": 18,\n",
    "    \"W\": 19,\n",
    "    \"Y\": 20,\n",
    "    \"^\": 21,\n",
    "    \"}\": 22,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cbcf77",
   "metadata": {},
   "source": [
    "# Train Baseline models\n",
    "\n",
    "Train individual PROSIT models for each cross-validation split, selecting the best model over a fixed number of epochs each. These models serve as baseline for performing uncertainty prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c615c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "for ds,EPOCHS,tc in [('median',60,'median'), ('sel10',10,'indexed_retention_time')]:\n",
    "    for cv in range(6):\n",
    "        print(\"\\n#####\", ds, cv, '#####\\n')\n",
    "        if os.path.exists(f'output_{ds}/cv{cv}/history.pkl'):\n",
    "            continue\n",
    "        set_global_seed(42)\n",
    "        \n",
    "        TRAIN_DATAPATH = f'../data/PROSPECT_{ds}_training{cv}.csv'\n",
    "        rtdata = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                                      seq_length=30, batch_size=BATCH_SIZE, val_ratio=0., test=False,\n",
    "                                      sequence_col='modified_sequence_single_letter',\n",
    "                                      target_col=tc)\n",
    "        VALIDATION_DATAPATH = f'../data/PROSPECT_median_validation{cv}.csv'\n",
    "        validation_rtdata = RetentionTimeDataset(data_source=VALIDATION_DATAPATH,\n",
    "                                      seq_length=30, batch_size=BATCH_SIZE, val_ratio=1., test=False,\n",
    "                                      sequence_col='modified_sequence_single_letter',\n",
    "                                      target_col='median')\n",
    "        TEST_DATAPATH = f'../data/PROSPECT_median_holdout_cv.csv'\n",
    "        test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                      seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                      sequence_col='modified_sequence_single_letter',\n",
    "                                      target_col='median')\n",
    "        test_targets = test_rtdata.get_split_targets(split=\"test\")\n",
    "\n",
    "        model = PrositRetentionTimePredictor(seq_length=30, vocab_dict=ALPHABET_MOD)\n",
    "\n",
    "        # setup a learning rate schedule\n",
    "        train_steps = BATCH_SIZE * len(rtdata.train_data) * EPOCHS\n",
    "        lr_fn = tf.optimizers.schedules.PolynomialDecay(1e-3, train_steps, 1e-6, 2)\n",
    "        opt = tf.optimizers.Adam(lr_fn)\n",
    "\n",
    "            model.compile(optimizer=opt, \n",
    "                          loss='mse',\n",
    "                          metrics=['mean_absolute_error', TimeDeltaMetric()])\n",
    "\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(f\"./output_{ds}/cv{cv}/\", f'best'),\n",
    "            save_weights_only=True,\n",
    "            monitor='val_timedelta',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        history = model.fit(rtdata.train_data,\n",
    "                        validation_data=validation_rtdata.val_data,\n",
    "                        callbacks=[model_checkpoint_callback],\n",
    "                        epochs=EPOCHS,\n",
    "                        verbose=2)\n",
    "        report = RetentionTimeReport(output_path=f\"./output_{ds}/cv{cv}\", history=history)\n",
    "        report.plot_keras_metric(\"loss\")\n",
    "        report.plot_keras_metric(\"mean_absolute_error\")\n",
    "        report.plot_keras_metric(\"timedelta\")\n",
    "        best_model = PrositRetentionTimePredictor(seq_length=30, vocab_dict=ALPHABET_MOD)\n",
    "        best_model.load_weights(f\"./output_{ds}/cv{cv}/best\")\n",
    "        predictions = best_model.predict(test_rtdata.test_data)\n",
    "        predictions = predictions.ravel()\n",
    "        with open(f'output_{ds}/cv{cv}/r2.txt', 'w') as f:\n",
    "            print(report.calculate_r2(test_targets, predictions), file=f)\n",
    "        report.plot_density(test_targets, predictions)\n",
    "        report.plot_residuals(test_targets, predictions, xrange=(-30, 30))\n",
    "        import pickle\n",
    "        with open(f'output_{ds}/cv{cv}/history.pkl', 'wb') as f:\n",
    "            pickle.dump(history, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
