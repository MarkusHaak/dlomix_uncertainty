{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc01e34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# install https://github.com/MarkusHaak/dlomix/ with pip\n",
    "# OR uncomment to insert its path with sys:\n",
    "#import os, sys\n",
    "#sys.path.insert(0, os.path.abspath('../../dlomix/'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1514218",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set global seeds for reproducibility\n",
    "from dlomix.utils import set_global_seed\n",
    "set_global_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "592919bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import dlomix\n",
    "from dlomix import constants, data, eval, layers, models, pipelines, reports, utils\n",
    "import traceback\n",
    "from dlomix.data import RetentionTimeDataset\n",
    "import pickle\n",
    "import os\n",
    "from dlomix.models import PrositRetentionTimePredictor\n",
    "from dlomix.reports import RetentionTimeReport\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy.stats import ks_2samp\n",
    "import tensorflow as tf\n",
    "from dlomix.losses.quantile import QuantileLoss\n",
    "from dlomix.eval.interval_conformal import IntervalSize, AbsoluteIntervalSize, RelativeCentralDistance, \\\n",
    "                                           IntervalConformalScore, IntervalConformalQuantile\n",
    "from scipy.stats import ks_2samp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f662e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphabet using the same PTM identifiers as in the created datasets\n",
    "ALPHABET_MOD = {\n",
    "    \"A\": 1,\n",
    "    \"C\": 2,\n",
    "    \"D\": 3,\n",
    "    \"E\": 4,\n",
    "    \"F\": 5,\n",
    "    \"G\": 6,\n",
    "    \"H\": 7,\n",
    "    \"I\": 8,\n",
    "    \"K\": 9,\n",
    "    \"L\": 10,\n",
    "    \"M\": 11,\n",
    "    \"N\": 12,\n",
    "    \"P\": 13,\n",
    "    \"Q\": 14,\n",
    "    \"R\": 15,\n",
    "    \"S\": 16,\n",
    "    \"T\": 17,\n",
    "    \"V\": 18,\n",
    "    \"W\": 19,\n",
    "    \"Y\": 20,\n",
    "    \"^\": 21,\n",
    "    \"}\": 22,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcad0345",
   "metadata": {},
   "source": [
    "# Quantile Regression\n",
    "\n",
    "Run Quantile regression on (modified) baseline models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55186342",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary storing the configuration of all models that shall be testet under their given label\n",
    "models = {\n",
    "    'PRT_med_<-1>:2' : {'config':['PRT_median', -1, tf.keras.Sequential([tf.keras.layers.Dense(2)])]},\n",
    "    #'PRT_med_<-1>:32:2' : {'config':['PRT_median', -1, tf.keras.Sequential([tf.keras.layers.Dense(32, activation=\"relu\"),tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_med_<-1>:64:2' : {'config':['PRT_median', -1, tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\"),tf.keras.layers.Dense(2)])]},\n",
    "    #'PRT_med_<-1>:64(0.3):2' : {'config':['PRT_median', -1, tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\"),tf.keras.layers.Dropout(rate=0.3),tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_med_<-2>:<-1>:2' : {'config':['PRT_median', -2, tf.keras.Sequential([tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_med_:2' : {'config':['PRT_median', 0, tf.keras.Sequential([tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_sel10_<-1>:2' : {'config':['PRT_sel10', -1, tf.keras.Sequential([tf.keras.layers.Dense(2)])]},\n",
    "    #'PRT_sel10_<-1>:32:2' : {'config':['PRT_sel10', -1, tf.keras.Sequential([tf.keras.layers.Dense(32, activation=\"relu\"),tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_sel10_<-1>:64:2' : {'config':['PRT_sel10', -1, tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\"),tf.keras.layers.Dense(2)])]},\n",
    "    #'PRT_sel10_<-1>:64(0.3):2' : {'config':['PRT_sel10', -1, tf.keras.Sequential([tf.keras.layers.Dense(64, activation=\"relu\"),tf.keras.layers.Dropout(rate=0.3),tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_sel10_<-2>:<-1>:2' : {'config':['PRT_sel10', -2, tf.keras.Sequential([tf.keras.layers.Dense(2)])]},\n",
    "    'PRT_sel10_:2' : {'config':['PRT_sel10', 0, tf.keras.Sequential([tf.keras.layers.Dense(2)])]},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac51fee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(1,6):\n",
    "    for label in models:\n",
    "        BATCH_SIZE = 256\n",
    "        # load train, validation and calibration data for the respective cross-validation split, and the test data\n",
    "        TRAIN_DATAPATH = f'../data/PROSPECT_median_training{cv}.csv'\n",
    "        rtdata_median = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                                      seq_length=30, batch_size=BATCH_SIZE, val_ratio=0., test=False,\n",
    "                                      sequence_col='modified_sequence_single_letter',\n",
    "                                      target_col='median')\n",
    "        TRAIN_DATAPATH = f'../data/PROSPECT_sel10_training{cv}.csv'\n",
    "        rtdata_sel10 = RetentionTimeDataset(data_source=TRAIN_DATAPATH,\n",
    "                                      seq_length=30, batch_size=BATCH_SIZE, val_ratio=0., test=False,\n",
    "                                      sequence_col='modified_sequence_single_letter',\n",
    "                                      target_col='indexed_retention_time')\n",
    "        VALIDATION_DATAPATH = f'../data/PROSPECT_median_validation{cv}.csv'\n",
    "        validation_rtdata = RetentionTimeDataset(data_source=VALIDATION_DATAPATH,\n",
    "                                                 seq_length=30, batch_size=BATCH_SIZE, val_ratio=1., test=False,\n",
    "                                                 sequence_col='modified_sequence_single_letter',\n",
    "                                                 target_col='median')\n",
    "        CALIBRATION_DATAPATH = f'../data/PROSPECT_median_calibration{cv}.csv'\n",
    "        calibration_rtdata = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                           seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                           sequence_col='modified_sequence_single_letter',\n",
    "                                           target_col='median')\n",
    "        calibration_targets = calibration_rtdata.get_split_targets(split=\"test\")\n",
    "        TEST_DATAPATH = '../data/PROSPECT_median_holdout_cv.csv'\n",
    "        test_rtdata = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                           seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                           sequence_col='modified_sequence_single_letter',\n",
    "                                           target_col='median')\n",
    "        test_targets = test_rtdata.get_split_targets(split=\"test\")\n",
    "    \n",
    "    \n",
    "        print(\"\\n#####\", label, cv, '#####\\n')\n",
    "        models[label][cv] = {}\n",
    "        model_class, frozen, output_layer = models[label]['config']\n",
    "        output_dir = f\"output_{label}/cv{cv}/\"\n",
    "        if model_class == 'PRT_median':\n",
    "            model_save_path = f\"./output_median/cv{cv}/best\"\n",
    "            rtdata = rtdata_median\n",
    "            epochs = 50\n",
    "        elif model_class == 'PRT_sel10':\n",
    "            model_save_path = f\"./output_sel10/cv{cv}/best\"\n",
    "            rtdata = rtdata_sel10\n",
    "            epochs = 6\n",
    "        \n",
    "        # in case this notebook crashes, don't rerun experiments\n",
    "        if os.path.exists(os.path.join(output_dir, \"history.pkl\")):\n",
    "            continue\n",
    "        set_global_seed(42)\n",
    "        \n",
    "        # load weights and define which layers are re-trained based on config\n",
    "        qr_model = PrositRetentionTimePredictor(seq_length=30, vocab_dict=ALPHABET_MOD)\n",
    "        if frozen:\n",
    "            qr_model.load_weights(model_save_path)\n",
    "            for layer in qr_model.layers[:frozen]:\n",
    "                layer.trainable = False\n",
    "        qr_model.output_layer = output_layer\n",
    "\n",
    "        # setup a learning rate schedule\n",
    "        train_steps = BATCH_SIZE * len(rtdata.train_data) * epochs\n",
    "        lr_fn = tf.optimizers.schedules.PolynomialDecay(1e-3, train_steps, 1e-6, 2)\n",
    "        opt = tf.optimizers.Adam(lr_fn)\n",
    "\n",
    "        qr_model.compile(optimizer=opt, \n",
    "                  loss=QuantileLoss(tf.constant([[0.1, 0.9]])),\n",
    "                  metrics=['mean_absolute_error', \n",
    "                           RelativeCentralDistance(),\n",
    "                           IntervalConformalQuantile(alpha=0.1),\n",
    "                           AbsoluteIntervalSize(),\n",
    "                          ])\n",
    "        # save best model based on validation loss\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=os.path.join(output_dir, 'best'),\n",
    "            save_weights_only=True,\n",
    "            monitor='val_loss',\n",
    "            mode='min',\n",
    "            save_best_only=True)\n",
    "        history = qr_model.fit(rtdata.train_data,\n",
    "                               validation_data=validation_rtdata.val_data,\n",
    "                               callbacks=[model_checkpoint_callback],\n",
    "                               epochs=epochs,\n",
    "                               verbose=2)\n",
    "        with open(os.path.join(output_dir,'history.pkl'), 'wb') as f:\n",
    "            pickle.dump(history, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c25c5bf",
   "metadata": {},
   "source": [
    "# Conformal Prediciton (median datasets)\n",
    "\n",
    "After Quantile Regression, apply conformal Prediction with alpha = 0.1 to assure marginal coverage of 0.9 for each model.\n",
    "The same is done for a randomized background model that is identical to the original model with respect to the heuristic interval sizes, but they are randomly reassociated betwee the test datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60874750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_conformal_scores(conf_scores, quantile=None, xlim=6):\n",
    "    fig,ax = plt.subplots()\n",
    "    xmax = conf_scores.std() * xlim\n",
    "    ax.hist(conf_scores[conf_scores < xmax], bins=100)\n",
    "    if quantile:\n",
    "        ax.axvline(quantile, color='red', alpha=0.5)\n",
    "    ax.set(xlabel='conformal score', ylabel='# per bin', title=f'conformal scores (<{xlim} std.dev. from mean)')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8d50a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for cv in range(1,6):\n",
    "    for label in models:\n",
    "        output_dir = f\"output_{label}/cv{cv}/\"\n",
    "        # skip experiments were quantile regression was not successful\n",
    "        if not os.path.exists(os.path.join(output_dir, 'history.pkl')):\n",
    "            continue\n",
    "        \n",
    "        # load calibration data for calculation of conformal scores\n",
    "        CALIBRATION_DATAPATH = f'../data/PROSPECT_median_calibration{cv}.csv'\n",
    "        calibration_rtdata = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                           seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                           sequence_col='modified_sequence_single_letter',\n",
    "                                           target_col='median')\n",
    "        calibration_targets = calibration_rtdata.get_split_targets(split=\"test\")\n",
    "        \n",
    "        # load best model from weights\n",
    "        model_class, frozen, output_layer = models[label]['config']\n",
    "        qr_model = PrositRetentionTimePredictor(seq_length=30, vocab_dict=ALPHABET_MOD)\n",
    "        qr_model.output_layer = output_layer\n",
    "        qr_model.load_weights(os.path.join(output_dir, \"best\"))\n",
    "        models[label][cv]['model'] = qr_model\n",
    "\n",
    "        # predict quantiles for calibration data, then calculate conformal scores and correct test-intervals accordingly\n",
    "        quantile_predictions = qr_model.predict(calibration_rtdata.test_data)\n",
    "        conf_scores = IntervalConformalScore(reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        conf_quantile = IntervalConformalQuantile(alpha=0.1, reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        intervals = qr_model.predict(test_rtdata.test_data)\n",
    "        intervals[:,0] -= conf_quantile\n",
    "        intervals[:,1] += conf_quantile\n",
    "\n",
    "        # calculate some other stats\n",
    "        interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "        within = (test_targets >= intervals[:,0]) & (test_targets <= intervals[:,1])\n",
    "        pvalue = ks_2samp(interval_sizes[within], interval_sizes[~within]).pvalue # prob. for Null: distr are identical\n",
    "\n",
    "        models[label][cv]['intervals'] = intervals\n",
    "        models[label][cv]['conf_scores'] = conf_scores\n",
    "        models[label][cv]['conf_quantile'] = conf_quantile\n",
    "        models[label][cv]['within'] = within\n",
    "        models[label][cv]['conf_scores_test'] = IntervalConformalScore(reduction='none')(np.expand_dims(test_targets,-1), qr_model.predict(test_rtdata.test_data)).numpy()\n",
    "        models[label][cv]['pvalue'] = pvalue\n",
    "\n",
    "        # plot conformal score distributions\n",
    "        print('####', label, cv, '####\\nconformal quantile:', conf_quantile, '\\n')\n",
    "        plot_conformal_scores(conf_scores, quantile=conf_quantile)\n",
    "        \n",
    "        # calculate a random background model\n",
    "        quantile_predictions = qr_model.predict(calibration_rtdata.test_data)\n",
    "        centers = (quantile_predictions[:,1] + quantile_predictions[:,0]) / 2\n",
    "        half_iv = (quantile_predictions[:,1] - quantile_predictions[:,0]) / 2\n",
    "        np.random.seed(42)\n",
    "        p = np.random.permutation(quantile_predictions.shape[0])\n",
    "        quantile_predictions = np.column_stack([centers - half_iv[p], centers + half_iv[p]])\n",
    "        \n",
    "        # perform conformalization for random background model\n",
    "        conf_scores = IntervalConformalScore(reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        conf_quantile = IntervalConformalQuantile(alpha=0.1, reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        intervals = qr_model.predict(test_rtdata.test_data)\n",
    "        centers = (intervals[:,1] + intervals[:,0]) / 2\n",
    "        half_iv = (intervals[:,1] - intervals[:,0]) / 2\n",
    "        np.random.seed(cv)\n",
    "        p = np.random.permutation(intervals.shape[0])\n",
    "        intervals = np.column_stack([centers - half_iv[p], centers + half_iv[p]])\n",
    "        intervals[:,0] -= conf_quantile\n",
    "        intervals[:,1] += conf_quantile\n",
    "\n",
    "        interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "        within = (test_targets >= intervals[:,0]) & (test_targets <= intervals[:,1])\n",
    "        models[label][cv]['rnd_conf_scores'] = conf_scores\n",
    "        models[label][cv]['rnd_conf_quantile'] = conf_quantile\n",
    "        models[label][cv]['rnd_intervals'] = intervals\n",
    "        models[label][cv]['rnd_within'] = within"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cb82472",
   "metadata": {},
   "source": [
    "# Visualize some results\n",
    "\n",
    "Plot interval size distributions for each individual model.\n",
    "\n",
    "This section is optional and can be skipped."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a823bbad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_predictions_with_intervals(test_targets, test_estimates, intervals, label=None):\n",
    "    fig,ax = plt.subplots()\n",
    "    if label:\n",
    "        ax.set_title(label)\n",
    "    p = test_targets.argsort()\n",
    "    ax.plot(test_targets[p], intervals[p, 0], alpha=0.1)\n",
    "    ax.plot(test_targets[p], intervals[p, 1], alpha=0.1)\n",
    "    ax.scatter(test_targets[p], test_estimates[p], s=1, alpha=0.1)\n",
    "    ax.plot((test_targets.min(),test_targets.max()), (test_targets.min(),test_targets.max()), alpha=0.3, color='black', linestyle='--')\n",
    "    ax.set(title=f'{label+\" \" if label else \"\"}predictions with error intervals, sorted by RT',\n",
    "           xlabel='true retention time',\n",
    "           ylabel='predicted retention time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3105bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot interval size distributions\n",
    "for label in models:\n",
    "    for cv in range(1,6):\n",
    "        output_dir = f\"output_{label}/cv{cv}/\"\n",
    "        if not os.path.exists(os.path.join(output_dir, 'history.pkl')):\n",
    "            continue\n",
    "        intervals = models[label][cv]['intervals']\n",
    "        print(intervals.shape)\n",
    "        interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "\n",
    "        print('####', label, cv, '####')\n",
    "        xlim = 6.\n",
    "        fig,ax = plt.subplots()\n",
    "        xmin = interval_sizes.mean() - interval_sizes.std() * xlim\n",
    "        xmax = interval_sizes.mean() + interval_sizes.std() * xlim\n",
    "        ax.hist(interval_sizes, bins=200, range=(0,60))#[(interval_sizes >= xmin) & (interval_sizes <= xmax)], bins=100)\n",
    "\n",
    "        ax.set(xlim=(0,60), ylim=(0,15000))\n",
    "        ax.set(xlabel='interval size', ylabel='# per bin', title=f'conformalized interval sizes')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ff5fbd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for label in models:\n",
    "    for cv in range(6):\n",
    "        output_dir = f\"output_{label}/cv{cv}/\"\n",
    "        if not os.path.exists(os.path.join(output_dir, 'history.pkl')):\n",
    "            continue\n",
    "        intervals = models[label][cv]['intervals']\n",
    "        print(intervals.shape)\n",
    "        interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "        within = (test_targets >= intervals[:,0]) & (test_targets <= intervals[:,1])\n",
    "\n",
    "        print('####', label, cv, '####')\n",
    "\n",
    "        pvalue = ks_2samp(interval_sizes[within], interval_sizes[~within]).pvalue # prob. for Null: distr are identical\n",
    "        print(f\"p = {pvalue:.5f} : {'Reject' if pvalue < 0.01 else 'Accept'} Null Hypothesis (Distr. identical)\")\n",
    "\n",
    "        xlim = 6.\n",
    "        fig,ax = plt.subplots()\n",
    "        xmin = interval_sizes.mean() - interval_sizes.std() * xlim\n",
    "        xmax = interval_sizes.mean() + interval_sizes.std() * xlim\n",
    "        ax.hist(interval_sizes[within], bins=100, range=(0,60), histtype='step', density=True, color='C0', label='inside interval')\n",
    "        ax.hist(interval_sizes[~within], bins=100, range=(0,60), histtype='step', density=True, color='C1', label='outside interval')\n",
    "\n",
    "        ax.set(xlim=(0,60), ylim=(0,0.42))\n",
    "        ax.set(xlabel='interval size', ylabel='fraction per bin', title=f'PDF of conformalized interval sizes')\n",
    "        ax.text(0.98, 0.8, f\"identical: p = {pvalue:.5f}\", transform=ax.transAxes, ha='right', va='top')\n",
    "        ax.legend()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a3f5b6b",
   "metadata": {},
   "source": [
    "# Conformal Prediciton (sel10 datasets)\n",
    "\n",
    "Do conformal prediction, as above, but use sel10 calibration and test data (up to 10 raw iRT values per unique sequence) instead of median ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d15a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEST_DATAPATH = '../data/PROSPECT_sel10_holdout_cv.csv'\n",
    "test_rtdata_sel10 = RetentionTimeDataset(data_source=TEST_DATAPATH,\n",
    "                                   seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                   sequence_col='modified_sequence_single_letter',\n",
    "                                   target_col='indexed_retention_time')\n",
    "test_targets_sel10 = test_rtdata_sel10.get_split_targets(split=\"test\")\n",
    "\n",
    "# copy config from the \"median\" results dictionary\n",
    "models_sel10 = {l:{'config':models[l]['config']} for l in models}\n",
    "\n",
    "for cv in range(6):\n",
    "    for label in models_sel10:\n",
    "        output_dir = f\"output_{label}/cv{cv}/\"\n",
    "        if not os.path.exists(os.path.join(output_dir, 'history.pkl')):\n",
    "            continue\n",
    "        models_sel10[label][cv] = {}\n",
    "        \n",
    "        # load calibration data for calculation of conformal scores\n",
    "        CALIBRATION_DATAPATH = f'../data/PROSPECT_sel10_calibration{cv}.csv'\n",
    "        calibration_rtdata = RetentionTimeDataset(data_source=CALIBRATION_DATAPATH,\n",
    "                                           seq_length=30, batch_size=BATCH_SIZE, test=True,\n",
    "                                           sequence_col='modified_sequence_single_letter',\n",
    "                                           target_col='indexed_retention_time')\n",
    "        calibration_targets = calibration_rtdata.get_split_targets(split=\"test\")\n",
    "        \n",
    "        # load best model from weights\n",
    "        model_class, frozen, output_layer = models_sel10[label]['config']\n",
    "        qr_model = PrositRetentionTimePredictor(seq_length=30, vocab_dict=ALPHABET_MOD)\n",
    "        qr_model.output_layer = output_layer\n",
    "        qr_model.load_weights(os.path.join(output_dir, \"best\"))\n",
    "        models_sel10[label][cv]['model'] = qr_model\n",
    "\n",
    "        # predict quantiles for calibration data, then calculate conformal scores and correct test-intervals accordingly\n",
    "        quantile_predictions = qr_model.predict(calibration_rtdata.test_data)\n",
    "        conf_scores = IntervalConformalScore(reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        conf_quantile = IntervalConformalQuantile(alpha=0.1, reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        intervals = qr_model.predict(test_rtdata_sel10.test_data)\n",
    "        intervals[:,0] -= conf_quantile\n",
    "        intervals[:,1] += conf_quantile\n",
    "        \n",
    "        # calculate some other stats\n",
    "        interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "        within = (test_targets_sel10 >= intervals[:,0]) & (test_targets_sel10 <= intervals[:,1])\n",
    "        pvalue = ks_2samp(interval_sizes[within], interval_sizes[~within]).pvalue # prob. for Null: distr are identical\n",
    "\n",
    "        models_sel10[label][cv]['intervals'] = intervals\n",
    "        models_sel10[label][cv]['conf_scores'] = conf_scores\n",
    "        models_sel10[label][cv]['conf_quantile'] = conf_quantile\n",
    "        models_sel10[label][cv]['within'] = within\n",
    "        models_sel10[label][cv]['conf_scores_test'] = IntervalConformalScore(reduction='none')(np.expand_dims(test_targets_sel10,-1), \n",
    "                                                                                               qr_model.predict(test_rtdata_sel10.test_data)).numpy()\n",
    "        models_sel10[label][cv]['pvalue'] = pvalue\n",
    "\n",
    "        print('####', label, cv, '####\\nconformal quantile:', conf_quantile, '\\n')\n",
    "        plot_conformal_scores(conf_scores, quantile=conf_quantile)\n",
    "        #plot_predictions_with_intervals(test_targets, new_predictions, intervals)\n",
    "        \n",
    "        # calculate a random background model\n",
    "        quantile_predictions = qr_model.predict(calibration_rtdata.test_data)\n",
    "        centers = (quantile_predictions[:,1] + quantile_predictions[:,0]) / 2\n",
    "        half_iv = (quantile_predictions[:,1] - quantile_predictions[:,0]) / 2\n",
    "        np.random.seed(42)\n",
    "        p = np.random.permutation(quantile_predictions.shape[0])\n",
    "        quantile_predictions = np.column_stack([centers - half_iv[p], centers + half_iv[p]])\n",
    "        \n",
    "        # perform conformalization for random background model\n",
    "        conf_scores = IntervalConformalScore(reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        conf_quantile = IntervalConformalQuantile(alpha=0.1, reduction='none')(np.expand_dims(calibration_targets,-1), quantile_predictions).numpy()\n",
    "        intervals = qr_model.predict(test_rtdata_sel10.test_data)\n",
    "        centers = (intervals[:,1] + intervals[:,0]) / 2\n",
    "        half_iv = (intervals[:,1] - intervals[:,0]) / 2\n",
    "        np.random.seed(cv)\n",
    "        p = np.random.permutation(intervals.shape[0])\n",
    "        intervals = np.column_stack([centers - half_iv[p], centers + half_iv[p]])\n",
    "        intervals[:,0] -= conf_quantile\n",
    "        intervals[:,1] += conf_quantile\n",
    "\n",
    "        interval_sizes = intervals[:,1] - intervals[:,0]\n",
    "        within = (test_targets_sel10 >= intervals[:,0]) & (test_targets_sel10 <= intervals[:,1])\n",
    "        models_sel10[label][cv]['rnd_conf_scores'] = conf_scores\n",
    "        models_sel10[label][cv]['rnd_conf_quantile'] = conf_quantile\n",
    "        models_sel10[label][cv]['rnd_intervals'] = intervals\n",
    "        models_sel10[label][cv]['rnd_within'] = within\n",
    "        print('####', label, cv, 'rnd', '####\\nconformal quantile:', conf_quantile, '\\n')\n",
    "        plot_conformal_scores(conf_scores, quantile=conf_quantile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad615004",
   "metadata": {},
   "source": [
    "# Save results as pickle files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba485824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete all TF objects (models, config and histories) from dict. \n",
    "# For whatever reason, they cannot be loaded correctly when pickled\n",
    "for label in models:\n",
    "    try:\n",
    "        del models[label]['config']\n",
    "    except:\n",
    "        pass\n",
    "    for cv in range(6):\n",
    "        try:\n",
    "            del models[label][cv]['model']\n",
    "            del models[label][cv]['history']\n",
    "        except:\n",
    "            pass\n",
    "for label in models:\n",
    "    try:\n",
    "        del models_sel10[label]['config']\n",
    "    except:\n",
    "        pass\n",
    "    for cv in range(6):\n",
    "        try:\n",
    "            del models_sel10[label][cv]['model']\n",
    "            del models_sel10[label][cv]['history']\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46db7a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/QR_results_cv_with_rnd.pkl', 'wb') as f:\n",
    "    pickle.dump(models, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c16e872",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/QR_results_sel10_cv_with_rnd.pkl', 'wb') as f:\n",
    "    pickle.dump(models_sel10, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
